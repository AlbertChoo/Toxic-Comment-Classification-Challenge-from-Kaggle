{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNQSZwj4ScU-"
      },
      "source": [
        "# Toxic Comment Classification Challenge\n",
        "- 6 classes of toxic\n",
        "- Create a prediction model which predict probs of toxicity for each comment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4i71VCFS18c"
      },
      "source": [
        "# 0. Check Version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpvvSOipTNF3"
      },
      "source": [
        "## Package Version and datetime last run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aAJGI384ogJ",
        "outputId": "6f5549cc-f1be-4af0-9c44-b4a24779a309"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow==2.14.0\n",
        "# !pip install tensorflow_hub==0.15.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9T62cDnSZeD",
        "outputId": "9d3ba846-066a-4446-c042-ec5891dc657d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datetime last run (end-to-end): 2024-09-12 12:08:38.741579\n",
            "2.14.0\n",
            "0.15.0\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f'Datetime last run (end-to-end): {datetime.datetime.now()}')\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "print(tf.__version__)\n",
        "print(hub.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LBZAIjbTGng"
      },
      "source": [
        "## Import Helper Functions and Dataset\n",
        "- Dataset imported from local disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Re3NL0b5TCsr"
      },
      "outputs": [],
      "source": [
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys, calculate_results, compare_baseline_to_new_results\n",
        "\n",
        "SAVE_DIR = 'model_logs'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcifoN-EVWYp"
      },
      "source": [
        "# 1. Visualize Txt Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCYrSjXlVYh_"
      },
      "source": [
        "## 1.1 DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GOKxAAJVX87",
        "outputId": "5747dca0-8963-4032-9512-7acc8e461cb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(                 id                                       comment_text  toxic  \\\n",
              " 0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              " 1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              " 2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              " 3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              " 4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              " \n",
              "    severe_toxic  obscene  threat  insult  identity_hate  \n",
              " 0             0        0       0       0              0  \n",
              " 1             0        0       0       0              0  \n",
              " 2             0        0       0       0              0  \n",
              " 3             0        0       0       0              0  \n",
              " 4             0        0       0       0              0  ,\n",
              "                  id                                       comment_text\n",
              " 0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
              " 1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
              " 2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
              " 3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
              " 4  00017695ad8997eb          I don't anonymously edit articles at all.)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head(), test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total multi-label samples: 9865\n",
            "Total single-label samples: 149706\n"
          ]
        }
      ],
      "source": [
        "# List the columns\n",
        "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# Check if any row has more than one label as 1\n",
        "train_df_copy = train_df.copy()\n",
        "train_df_copy['multi_label_count'] = train_df[target_cols].sum(axis=1)\n",
        "multi_label_samples = train_df_copy[train_df_copy['multi_label_count'] > 1]\n",
        "\n",
        "print(f\"Total multi-label samples: {len(multi_label_samples)}\")\n",
        "print(f\"Total single-label samples: {len(train_df_copy) - len(multi_label_samples)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So it is a multi-label problem (Comments can be labeled as multiple types of toxic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKnAvZ-WCE5"
      },
      "source": [
        "## 1.2 Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xo0GSa8qVgoI"
      },
      "outputs": [],
      "source": [
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxiFuX0UXi9x"
      },
      "source": [
        "## 1.3 `value_counts`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqQ2LpToXSOc",
        "outputId": "e9f84376-faea-4917-eceb-a525d38d1dad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Value counts for column 'toxic':\n",
            "\n",
            "toxic\n",
            "0    144277\n",
            "1     15294\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for column 'severe_toxic':\n",
            "\n",
            "severe_toxic\n",
            "0    157976\n",
            "1      1595\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for column 'obscene':\n",
            "\n",
            "obscene\n",
            "0    151122\n",
            "1      8449\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for column 'threat':\n",
            "\n",
            "threat\n",
            "0    159093\n",
            "1       478\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for column 'insult':\n",
            "\n",
            "insult\n",
            "0    151694\n",
            "1      7877\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for column 'identity_hate':\n",
            "\n",
            "identity_hate\n",
            "0    158166\n",
            "1      1405\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "columns_to_count = train_df.drop(['id', 'comment_text'], axis=1)\n",
        "\n",
        "for column in columns_to_count:\n",
        "    value_counts = columns_to_count[column].value_counts()\n",
        "    print(f\"\\nValue counts for column '{column}':\\n\")\n",
        "    print(value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJGWSH8SXoLZ",
        "outputId": "19c8ce77-b2cf-4e29-db05-30d028aa53eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 159571\n",
            "Test: 153164\n",
            "Total: 312735\n"
          ]
        }
      ],
      "source": [
        "print(f'Training: {len(train_df_shuffled)}')\n",
        "print(f'Test: {len(test_df)}')\n",
        "print(f'Total: {len(train_df_shuffled) + len(test_df)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwgRxkM7ZBw3"
      },
      "source": [
        "## 1.4 Split train validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT6xFoDzY1VG",
        "outputId": "8e1fcbee-7a24-4371-aad4-b571e255c0df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(143613, 143613, 15958, 15958)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_comment, val_comment, train_labels, val_labels = train_test_split(train_df_shuffled['comment_text'].to_numpy(),\n",
        "                                                                        train_df_shuffled.drop(['id', 'comment_text'], axis=1).to_numpy(),\n",
        "                                                                        test_size=0.1,\n",
        "                                                                        random_state=42)\n",
        "len(train_comment), len(train_labels), len(val_comment), len(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyK7Px1nZUty",
        "outputId": "2609aaa7-6e38-4b34-8df2-19a74fdaadc2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['\"\\n\\nDanilovic\\nAlright, we\\'ll stay away from value-judgement, although when you\\'ve got a documented rap sheet as long as Danilovic\\'s, \"\"surly\"\" is almost a compliment. \\nYes, Blic is a reliable source. It\\'s one of the high-circulation dailies in Serbia. Yes, it\\'s a middle-market tabloid, but it doesn\\'t invent stories. It\\'s very similar to Britain\\'s Daily Mail. Plus the case of Danilovic beating up referee Juras is well-documented in Serbian media as well as the resulting sanctions, both basketball-related and civic.  \"',\n",
              "        '\"\\n\\n Jeepers  \\nI just came looking for info on Madame Sosostris and I found this preening custerfluck instead. I thought I remembered the character from a modern opera called \"\"A Midsummer Marriage\"\", and then discovered the name was most likely inspired by T.S. Eliot\\'s poem, \"\"The Wasteland\"\", which, in turn, was inspred by Huxley?  Edit away. I just thought that if somebody came to this page it might be nice if they actually found some info on Madame Sosostris. \\n\\nAnd I hope you get over your Ashlee Simpson addiction. Truly, man, she\\'s not worth it.\"'],\n",
              "       dtype=object),\n",
              " array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_comment[:2], train_labels[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNsI1LGZ25T"
      },
      "source": [
        "# 2. Convert texts to numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8X2-GGmZ6Rx"
      },
      "source": [
        "## 2.1 Tokenization\n",
        "### 2.1.1. `max_length` - Find avg num of tokens in training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpx-U8eGZayn",
        "outputId": "3b9a345f-07ba-45cc-b0fd-e56a5ab89e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(67.33298517543676, 230, 1411)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "comment_length = [len(i.split()) for i in train_comment]\n",
        "np.mean(comment_length), int(np.percentile(comment_length, 95)), max(comment_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "irG51yYdcc3T",
        "outputId": "7754d0bb-a6c9-4cbe-86c1-f664e9c76b2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1.32448e+05, 7.85500e+03, 1.63700e+03, 9.57000e+02, 6.29000e+02,\n",
              "        6.40000e+01, 1.20000e+01, 1.10000e+01]),\n",
              " array([1.00000e+00, 1.77250e+02, 3.53500e+02, 5.29750e+02, 7.06000e+02,\n",
              "        8.82250e+02, 1.05850e+03, 1.23475e+03, 1.41100e+03]),\n",
              " <BarContainer object of 8 artists>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(comment_length, bins=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or-sCn6sctYJ"
      },
      "source": [
        "Sum: `max_length` for train_comment should be 230, now go for `max_vocab_length`\n",
        "## 2.1.2. `max_vocab_length`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxHWI2rgNHr",
        "outputId": "38dbcc92-af69-4eb1-cbdb-f20941a0dd6c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\ILLEGEAR\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\ILLEGEAR\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P_Qv-BUc_4R",
        "outputId": "96894a53-49b6-4629-80db-b1f819149a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max vocabulary length: 13\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Sample text\n",
        "text = \"This is a sample text for understanding max vocabulary length.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Create a vocabulary\n",
        "vocabulary = set(tokens)\n",
        "\n",
        "# Find the max vocabulary length\n",
        "print(\"Max vocabulary length:\", len(max(vocabulary, key=len)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHh9hzincs1F",
        "outputId": "5529374e-5b3e-49a4-f38d-d3eae1e8f528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max vocabulary length: 4958\n"
          ]
        }
      ],
      "source": [
        "vocabulary = set(word.lower() for comment in train_comment for word in comment.split())\n",
        "\n",
        "max_vocab_length = len(max(vocabulary, key=len))\n",
        "print(\"Max vocabulary length:\", max_vocab_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9EeOoF8di8P"
      },
      "source": [
        "## 2.2 Create Text Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hrpAW1-vdXR3"
      },
      "outputs": [],
      "source": [
        "max_length = 230\n",
        "max_vocab_length = 10000\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import tensorflow as tf\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(max_tokens=max_vocab_length,\n",
        "                                                    standardize='lower_and_strip_punctuation',\n",
        "                                                    output_sequence_length=max_length,\n",
        "                                                    output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xzzBvxIBegjx"
      },
      "outputs": [],
      "source": [
        "# Adapt it\n",
        "text_vectorizer.adapt(train_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pNuvzi4dyxf",
        "outputId": "794b7a86-b4ee-443f-fcd7-9089e455607f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "\"\n",
            "Good start, but most people will expect at least six months actively editing and 2,000 edits or so before considering supporting a candidate. Not that those people are me, but that's a de facto standard. — (talk) \"      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 230), dtype=int64, numpy=\n",
              "array([[  98,  432,   27,  133,   76,   44, 1101,   34,  295, 1803,  767,\n",
              "        3921,  116,    5, 2009,  123,   26,   37,  144, 1230, 1700,    6,\n",
              "        2600,   15,   10,  141,   76,   20,   36,   27,  176,    6,  928,\n",
              "        5236,  800,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
              "      dtype=int64)>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "random_comment = random.choice(train_comment)\n",
        "print(f'Original text:\\n{random_comment}\\\n",
        "      \\n\\nVectorized version:')\n",
        "text_vectorizer([random_comment])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpEuHOFCd-2Y",
        "outputId": "cff26612-de03-46f0-8611-aa105d61eae1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 10000\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'to', 'of']\n",
            "Least common words in the vocabulary: ['seeds', 'seed', 'safer', 'rw', 'rounds']\n"
          ]
        }
      ],
      "source": [
        "# How many words in our training vocabulary?\n",
        "x = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(x)}\"),\n",
        "print(f\"Most common words in the vocabulary: {x[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {x[-5:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDzUOAHke0KW",
        "outputId": "f3a88726-9e6e-4619-b6d7-d3a4ff4192c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 10000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 230,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 10000}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_vectorizer.get_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YnJHsOGgJtn"
      },
      "source": [
        "## 2.3 Create Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SogJEuLKfFfM",
        "outputId": "d9bf0769-f38f-4a47-fd21-b0cd1a8b5ef3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x1ec2f607940>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             mask_zero=True,\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length,\n",
        "                             name='embedding_1')\n",
        "embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn2H9hR8hDEf",
        "outputId": "e4f31c9c-2739-4443-82f6-b49a8d603fa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence before vectorization:\n",
            "\"\n",
            "Good start, but most people will expect at least six months actively editing and 2,000 edits or so before considering supporting a candidate. Not that those people are me, but that's a de facto standard. — (talk) \"\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[  98  432   27  133   76   44 1101   34  295 1803  767 3921  116    5\n",
            "  2009  123   26   37  144 1230 1700    6 2600   15   10  141   76   20\n",
            "    36   27  176    6  928 5236  800    1    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[ 0.03665829 -0.01243868  0.00891172 ... -0.02412651  0.00298679\n",
            "    0.0373636 ]\n",
            "  [ 0.04935218  0.02474154  0.03534669 ...  0.03243654  0.04783771\n",
            "    0.03471282]\n",
            "  [ 0.01769337 -0.04538074  0.00700014 ... -0.02586523 -0.04413493\n",
            "   -0.03096408]\n",
            "  ...\n",
            "  [-0.03193214 -0.01480433 -0.03586396 ... -0.01475994 -0.02799249\n",
            "    0.00087941]\n",
            "  [-0.03193214 -0.01480433 -0.03586396 ... -0.01475994 -0.02799249\n",
            "    0.00087941]\n",
            "  [-0.03193214 -0.01480433 -0.03586396 ... -0.01475994 -0.02799249\n",
            "    0.00087941]]]\n",
            "\n",
            "Embedded sentence shape: (1, 230, 128)\n"
          ]
        }
      ],
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{random_comment}\\n\")\n",
        "vectorized_sentence = text_vectorizer([random_comment])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = embedding(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lxT82aIhshr"
      },
      "source": [
        "## 2.4 Create datasets\n",
        "- `tf.data`\n",
        "- PrefetchDataset, `batch(), prefetch(), tf.data.AUTOTUNE()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akQXnK-PhI8L",
        "outputId": "d07af6eb-0ac1-4531-8f52-cb87432632ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_comment, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_comment, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "train_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8WkHWQMiGz2"
      },
      "source": [
        "# 3. Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRNRVHv5kN50"
      },
      "source": [
        "## 3.1 Baseline 1\n",
        "- Simpler, Efficient, but do not provide insights for each category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjwJJJ5qh93A",
        "outputId": "e265077e-dddf-48bd-cb24-ce922e96ca1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 0 score: 0.8991101641809751\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a OneVsRestClassifier with MultinomialNB as the base estimator\n",
        "model_0 = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', OneVsRestClassifier(MultinomialNB()))\n",
        "])\n",
        "\n",
        "model_0.fit(train_comment, train_labels)\n",
        "\n",
        "baseline_score = model_0.score(val_comment, val_labels)\n",
        "print(f\"Model 0 score: {baseline_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LPtcGky2n8I",
        "outputId": "a4997705-508f-4608-fae7-88189aeb9a73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_0_preds = model_0.predict(val_comment)\n",
        "model_0_preds[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynxPXz082vjO",
        "outputId": "aaf86245-65f2-4cab-e984-6d76ccf59eb9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ILLEGEAR\\anaconda3\\envs\\py3900\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'accuracy': 89.91101641809752,\n",
              " 'precision': 0.8798293651918689,\n",
              " 'recall': 0.10532244438186426,\n",
              " 'f1': 0.18522543349795792}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=model_0_preds)\n",
        "baseline_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-tszr-pkTNE"
      },
      "source": [
        "## 3.2 Baseline 2\n",
        "- **One-vs-rest** approach allows you to analyze the performance of each category and potentially fine-tune models individually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FJhRLp0lDVT"
      },
      "outputs": [],
      "source": [
        "type(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eao9Ayzkxhv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert train_labels back to a DataFrame\n",
        "train_labels1 = pd.DataFrame(train_labels)\n",
        "\n",
        "type(train_labels1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhkrMgPbiSJN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "models = []\n",
        "# Extract category names\n",
        "category_names = list(train_labels1.columns)\n",
        "\n",
        "for i in range(len(category_names)):\n",
        "    # Create a new label array with 1 for the current category and 0 for others\n",
        "    new_labels = train_labels1.iloc[:, i].copy()\n",
        "    new_labels[new_labels != 1] = 0  # Replace non-category values with 0\n",
        "\n",
        "    # Create and fit the model pipeline\n",
        "    model = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer()),\n",
        "        ('clf', MultinomialNB())\n",
        "    ])\n",
        "    model.fit(train_comment, new_labels)\n",
        "    models.append(model)\n",
        "\n",
        "# Evaluate each model using cross-validation (optional)\n",
        "scores = cross_val_score(models[0], train_comment, train_labels1.iloc[:, 0], cv=5)\n",
        "print(f\"Model 0 (toxic) CV score: {scores.mean()}\")\n",
        "\n",
        "# Repeat for other categories and scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcW-M2e03JL-"
      },
      "source": [
        "## 3.3 `Model_1` USE Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGeGot1A3sVw"
      },
      "source": [
        "### 3.3.1 Test USE Url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPx4N0dFkpTl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "embed = hub.load(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\")\n",
        "sample_sentence = 'There is a flood in my street'\n",
        "embed_samples = embed([sample_sentence,\n",
        "                      \"When you can the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2aKgo6r3t5X"
      },
      "source": [
        "### 3.3.2 Build Embedding Layer Using USE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI6SXSSi3w1p"
      },
      "outputs": [],
      "source": [
        "use_embed_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/universal-sentence-encoder/TensorFlow2/universal-sentence-encoder/2\",\n",
        "                                 input_shape=[],\n",
        "                                 dtype=tf.string,\n",
        "                                 trainable=False,\n",
        "                                 name='use')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHLXKgAP38hV"
      },
      "source": [
        "### 3.3.3 Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL4ZVcZ537Tb"
      },
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(), dtype=tf.string)\n",
        "x = use_embed_layer(inputs)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "outputs = layers.Dense(6, activation='sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_USE')\n",
        "\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "model_1.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_3WmRdJ4F0d"
      },
      "outputs": [],
      "source": [
        "model_1_history = model_1.fit(train_comment,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_comment, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name='model_logs',\n",
        "                                                                     experiment_name='model_1_USE')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqNoowdp7GRy"
      },
      "outputs": [],
      "source": [
        "model_1_preds = model_1.predict(val_comment)\n",
        "model_1_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkuIKTVC7Rzu"
      },
      "outputs": [],
      "source": [
        "model_1_preds_label = tf.argmax(model_1_preds, axis=1)\n",
        "model_1_preds_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlJTmOxQ_gB0"
      },
      "outputs": [],
      "source": [
        "val_labels[:5], model_1_preds_label[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt1hDdUA_tbh"
      },
      "outputs": [],
      "source": [
        "val_labels_tf = tf.convert_to_tensor(val_labels)\n",
        "val_labels_tf[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTxgOJKk-Pdw"
      },
      "outputs": [],
      "source": [
        "model_1_results = calculate_results(y_true=val_labels_tf,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CMBJayTUq54"
      },
      "source": [
        "## 3.4 `Model_2`: Conv1D with character embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBNyqXUUXXY_"
      },
      "source": [
        "### 3.4.1 Split sentences to characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "xw0u_60E-bng",
        "outputId": "8805dcef-5970-4839-f45f-4fef56c0bbb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"\\n\\n==WP Delinking Dates==\\n\\nCongratulations on being one of the most destuctrive forces on Wikipedia. Your campaign to delink dates ensures that scores of children won\\'t be at all concerned about history. \"'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "lg6U4-wNXVL0",
        "outputId": "1ed32d74-c988-49a3-d124-b47d1ed83c20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\" \\n \\n = = W P   D e l i n k i n g   D a t e s = = \\n \\n C o n g r a t u l a t i o n s   o n   b e i n g   o n e   o f   t h e   m o s t   d e s t u c t r i v e   f o r c e s   o n   W i k i p e d i a .   Y o u r   c a m p a i g n   t o   d e l i n k   d a t e s   e n s u r e s   t h a t   s c o r e s   o f   c h i l d r e n   w o n \\' t   b e   a t   a l l   c o n c e r n e d   a b o u t   h i s t o r y .   \"'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "split_chars(random_comment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6g7fWBNXra1"
      },
      "source": [
        "### 3.4.2 Create char-lvl datasets by splitting out sequence datasets into characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "1MW-wrFOXmaM",
        "outputId": "58063374-6223-498c-813b-91db57b97df1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\" \\n \\n D a n i l o v i c \\n A l r i g h t ,   w e \\' l l   s t a y   a w a y   f r o m   v a l u e - j u d g e m e n t ,   a l t h o u g h   w h e n   y o u \\' v e   g o t   a   d o c u m e n t e d   r a p   s h e e t   a s   l o n g   a s   D a n i l o v i c \\' s ,   \" \" s u r l y \" \"   i s   a l m o s t   a   c o m p l i m e n t .   \\n Y e s ,   B l i c   i s   a   r e l i a b l e   s o u r c e .   I t \\' s   o n e   o f   t h e   h i g h - c i r c u l a t i o n   d a i l i e s   i n   S e r b i a .   Y e s ,   i t \\' s   a   m i d d l e - m a r k e t   t a b l o i d ,   b u t   i t   d o e s n \\' t   i n v e n t   s t o r i e s .   I t \\' s   v e r y   s i m i l a r   t o   B r i t a i n \\' s   D a i l y   M a i l .   P l u s   t h e   c a s e   o f   D a n i l o v i c   b e a t i n g   u p   r e f e r e e   J u r a s   i s   w e l l - d o c u m e n t e d   i n   S e r b i a n   m e d i a   a s   w e l l   a s   t h e   r e s u l t i n g   s a n c t i o n s ,   b o t h   b a s k e t b a l l - r e l a t e d   a n d   c i v i c .     \"'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_chars = [split_chars(i) for i in train_comment]\n",
        "val_chars = [split_chars(i) for i in val_comment]\n",
        "train_chars[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7yymtQyYRnc",
        "outputId": "f5ce29f8-956d-4a78-d7b2-25b1252daabf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(787.6917201089038, 2711, 9999)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check what is the avg char length\n",
        "char_lens = [len(i) for i in train_chars]\n",
        "output_seq_char_lens = int(np.percentile(char_lens, 95))\n",
        "np.mean(char_lens), output_seq_char_lens, max(char_lens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "4PgqvheFYba5",
        "outputId": "226c5831-5186-4e41-c1cd-af78d9616045"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([113423.,  18211.,   5997.,   2362.,   1063.,    669.,    510.,\n",
              "           437.,    360.,    581.]),\n",
              " array([  11. , 1009.8, 2008.6, 3007.4, 4006.2, 5005. , 6003.8, 7002.6,\n",
              "        8001.4, 9000.2, 9999. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check distribution of our sequences at char-lvl\n",
        "plt.hist(char_lens, bins=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng8bsYMXYvX6"
      },
      "source": [
        "### 3.4.3 Create Tokenization Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dIWaeQo0YhY6",
        "outputId": "63659ba4-021d-461a-b9bb-9e856d98f9bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all keyboard chars for char-lvl embeddings\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "14Dj1L6HZE4w"
      },
      "outputs": [],
      "source": [
        "# Create char-lvl token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # Space + OOV\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_lens,\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    output_mode='int',\n",
        "                                    name='char_vectorizer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adapt char vectorizer to train_chars\n",
        "char_vectorizer.adapt(train_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "guEWpzTdZv3S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of different characters in character vocab: 70\n",
            "5 Most common characters: ['', '[UNK]', 'e', 't', 'a']\n",
            "5 Least common characters: ['ı', 'α', 'т', 'ä', 'с']\n"
          ]
        }
      ],
      "source": [
        "# Check vocab characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 Most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 Least common characters: {char_vocab[-5:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Fedod7nXaRF8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Charified text:\n",
            "I d i o c r a c y   \n",
            " \n",
            " I f   y o u   n e e d   a   1 3   s e c t i o n   F A Q   t o   j u s t i f y   y o u r   i d i o c y   t h e n   i t   i s   c l e a r   y o u r   b i a s   v i e w p o i n t   i s   w r o n g ,   r e n a m e   t h e   a r t i c l e   t o   M E G A   D R I V E   a n d   s t o p   b e i n g   i d i o t s . . . . 8 2 . 4 1 . 1 0 7 . 9 7     \n",
            " \n",
            " P l e a s e   d o   n o t   r e m o v e   m y   i n p u t   a g a i n . . .   i t   v i o l a t e s   W P : P R E S E R V E   W P : V A N D A L I S M   a n d   W P : N O T C E N S O R E D   a l s o   p l e a s e   s t o p   b e i n g   i d i o t   A m e r i c a n s   a n d   o f f e n d i n g   t h e   r e s t   o f   t h e   w o r l d   w i t h   y o u r   b a c k w a r d ,   b i a s e d   a n d   d i s t o r t e d   v i e w s   w h i c h   y o u   t r y   t o   f o r c e   u p o n   i s   l i k e   t h i s   a r t i c l e s   t i t l e 8 2 . 4 1 . 1 0 7 . 9 7\n",
            "\n",
            "Length of random_train_chars: 390\n",
            "\n",
            "Vectorized chars:\n",
            "[[ 5 12  5 ...  0  0  0]]\n",
            "\n",
            "Length of vectorized_chars: 2711\n"
          ]
        }
      ],
      "source": [
        "# Test out char_vect\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized_chars: {len(vectorized_chars[0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUm_vdb7agFa"
      },
      "source": [
        "### 3.4.4 Char-lvl Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "L1UQErmfaiPk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x16eac5e8340>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.random.set_seed(42)\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS,\n",
        "                              output_dim=128,\n",
        "                              embeddings_initializer='uniform',\n",
        "                              input_length=output_seq_char_lens,\n",
        "                              name='embedding_1')\n",
        "char_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ori: \"\n",
            "\n",
            "==WP Delinking Dates==\n",
            "\n",
            "Congratulations on being one of the most destuctrive forces on Wikipedia. Your campaign to delink dates ensures that scores of children won't be at all concerned about history. \"      \n",
            "\n",
            "Embedded:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2711, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03357713, -0.00152319, -0.02870076, ..., -0.04505892,\n",
              "         -0.0170892 ,  0.04813454],\n",
              "        [ 0.03357713, -0.00152319, -0.02870076, ..., -0.04505892,\n",
              "         -0.0170892 ,  0.04813454],\n",
              "        [ 0.03357713, -0.00152319, -0.02870076, ..., -0.04505892,\n",
              "         -0.0170892 ,  0.04813454],\n",
              "        ...,\n",
              "        [-0.01648936,  0.03550879,  0.0495749 , ...,  0.04656985,\n",
              "          0.04111593,  0.04639396],\n",
              "        [-0.01648936,  0.03550879,  0.0495749 , ...,  0.04656985,\n",
              "          0.04111593,  0.04639396],\n",
              "        [-0.01648936,  0.03550879,  0.0495749 , ...,  0.04656985,\n",
              "          0.04111593,  0.04639396]]], dtype=float32)>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get a random sentence from training set\n",
        "print(f\"Ori: {random_comment}\\\n",
        "      \\n\\nEmbedded:\")\n",
        "\n",
        "sample_embed = char_embed(char_vectorizer([random_comment]))\n",
        "sample_embed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4.5 Build Conv1D Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " char_vectorizer (TextVecto  (None, 2711)              0         \n",
            " rization)                                                       \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 2711, 128)         8960      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 2711, 64)          41024     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Gl  (None, 64)                0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50374 (196.77 KB)\n",
            "Trainable params: 50374 (196.77 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = char_embed(char_vectorizer(inputs))\n",
        "x = layers.Conv1D(64, kernel_size=5, padding='same', activation='relu')(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(6, activation='sigmoid')(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_Conv1D')\n",
        "\n",
        "model_2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Label Encoding (One Target Column)\n",
        "- Use for multi-class classification\n",
        "- `Dense(num_classes, activation='softmax')`\n",
        "- Loss: `categorical` (For one-hot), or `sparse` (For label)\n",
        "\n",
        "Keep Columns Separated (Multiple Binary Targets)\n",
        "- Use for Multi-Label Classification\n",
        "- `Dense(num_classes, activation='sigmoid')`\n",
        "- Loss: `binary`|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4.6 Create char-level batched `PrefetchDataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "448/448 [==============================] - 143s 319ms/step - loss: 0.0851 - accuracy: 0.9205 - val_loss: 0.0879 - val_accuracy: 0.8380\n",
            "Epoch 2/3\n",
            "448/448 [==============================] - 134s 299ms/step - loss: 0.0824 - accuracy: 0.9153 - val_loss: 0.0837 - val_accuracy: 0.8833\n",
            "Epoch 3/3\n",
            "448/448 [==============================] - 134s 300ms/step - loss: 0.0798 - accuracy: 0.9112 - val_loss: 0.0781 - val_accuracy: 0.8438\n"
          ]
        }
      ],
      "source": [
        "# Fit model on chars only\n",
        "model_2_history = model_2.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1*len(val_char_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "499/499 [==============================] - 26s 52ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.00316704, 0.00019774, 0.00107641, 0.00064655, 0.0025386 ,\n",
              "        0.00250135],\n",
              "       [0.0085618 , 0.00128876, 0.00452573, 0.00378456, 0.00585344,\n",
              "        0.00068364],\n",
              "       [0.02433012, 0.00080226, 0.01094374, 0.00090181, 0.00935942,\n",
              "        0.00699687],\n",
              "       ...,\n",
              "       [0.00464168, 0.00034234, 0.00628407, 0.00066191, 0.00433614,\n",
              "        0.00453767],\n",
              "       [0.00184888, 0.00037755, 0.00131398, 0.00038456, 0.00237037,\n",
              "        0.00182727],\n",
              "       [0.02075131, 0.00133719, 0.01656135, 0.00186973, 0.01031332,\n",
              "        0.00529115]], dtype=float32)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2_pred_probs = model_2.predict(val_char_dataset)\n",
        "model_2_pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 0, 0, 0, 0], dtype=int64)>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.5: `Model_3` GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5.1 Create embed and build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 230)               0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " embedding_GRU (Embedding)   (None, 230, 128)          1280000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 230, 64)           37248     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 64)                24960     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1342598 (5.12 MB)\n",
            "Trainable params: 1342598 (5.12 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "num_words = 10000\n",
        "embedding_dim = 128\n",
        "max_seq_len = 100\n",
        "num_classes = 6\n",
        "\n",
        "model_3_embed = Embedding(input_dim=num_words,\n",
        "                                 output_dim=embedding_dim,\n",
        "                                 input_length=max_seq_len,\n",
        "                                 embeddings_initializer='uniform',\n",
        "                                 name='embedding_GRU')\n",
        "\n",
        "inputs = Input(shape=(1,), dtype='string')\n",
        "x = model_3_embed(text_vectorizer(inputs))\n",
        "x = GRU(64, return_sequences=True)(x)\n",
        "x = GRU(64)(x)\n",
        "outputs = Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "model_3 = Model(inputs, outputs, name='model_3_GRU')\n",
        "model_3.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5.2 Take 10% of the data to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total training examples: 143613\n",
            "Length of 10% training examples: 14362\n"
          ]
        }
      ],
      "source": [
        "train_comment_90, train_comment_10, train_labels_90, train_labels_10 = train_test_split(np.array(train_comment),\n",
        "                                                                                        train_labels,\n",
        "                                                                                        test_size=0.1,\n",
        "                                                                                        random_state=42)\n",
        "\n",
        "print(f\"Total training examples: {len(train_comment)}\")\n",
        "print(f\"Length of 10% training examples: {len(train_comment_10)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.5.3 Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20240912-222923\n",
            "Epoch 1/5\n",
            "449/449 [==============================] - 148s 319ms/step - loss: 0.1533 - accuracy: 0.9925 - val_loss: 0.1430 - val_accuracy: 0.9937\n",
            "Epoch 2/5\n",
            "449/449 [==============================] - 128s 284ms/step - loss: 0.1395 - accuracy: 0.9949 - val_loss: 0.1428 - val_accuracy: 0.9937\n",
            "Epoch 3/5\n",
            "449/449 [==============================] - 128s 286ms/step - loss: 0.1396 - accuracy: 0.9949 - val_loss: 0.1428 - val_accuracy: 0.9936\n",
            "Epoch 4/5\n",
            "449/449 [==============================] - 147s 328ms/step - loss: 0.1260 - accuracy: 0.9790 - val_loss: 0.0778 - val_accuracy: 0.9935\n",
            "Epoch 5/5\n",
            "449/449 [==============================] - 179s 398ms/step - loss: 0.0606 - accuracy: 0.9951 - val_loss: 0.0662 - val_accuracy: 0.9937\n"
          ]
        }
      ],
      "source": [
        "model_3_history = model_3.fit(train_comment_10, train_labels_10,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_comment, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_3_GRU')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the GRU Model is that good, we can train on full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU_full/20240912-140544\n",
            "Epoch 1/5\n",
            "4488/4488 [==============================] - 933s 208ms/step - loss: 0.0510 - accuracy: 0.9927 - val_loss: 0.0519 - val_accuracy: 0.9924\n",
            "Epoch 2/5\n",
            "4488/4488 [==============================] - 790s 176ms/step - loss: 0.0438 - accuracy: 0.9926 - val_loss: 0.0480 - val_accuracy: 0.9883\n",
            "Epoch 3/5\n",
            "4488/4488 [==============================] - 789s 176ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0501 - val_accuracy: 0.9905\n",
            "Epoch 4/5\n",
            "4488/4488 [==============================] - 782s 174ms/step - loss: 0.0339 - accuracy: 0.9625 - val_loss: 0.0527 - val_accuracy: 0.8987\n",
            "Epoch 5/5\n",
            "4488/4488 [==============================] - 784s 175ms/step - loss: 0.0295 - accuracy: 0.9076 - val_loss: 0.0560 - val_accuracy: 0.9783\n"
          ]
        }
      ],
      "source": [
        "model_3_full_history = model_3.fit(train_comment, train_labels,\n",
        "                                   epochs=5,\n",
        "                                   validation_data=(val_comment, val_labels),\n",
        "                                   callbacks=[create_tensorboard_callback(SAVE_DIR, 'model_3_GRU_full')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_3_SavedModel_format\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_3_SavedModel_format\\assets\n"
          ]
        }
      ],
      "source": [
        "model_3.save(\"model_3_SavedModel_format\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Generate Predictions on `test_df`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "loaded_model = tf.keras.models.load_model(\"model_3_SavedModel_format\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "499/499 [==============================] - 22s 43ms/step - loss: 0.0662 - accuracy: 0.9937\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.06620540469884872, 0.9936708807945251]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model.evaluate(val_comment, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Re-structure `test.csv` and `test_labels.csv` to generate predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.1 Check files top 5 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('test.csv')\n",
        "test_labels = pd.read_csv('test_labels.csv')\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_comment, val_comment, train_labels, val_labels = train_test_split(train_df_shuffled['comment_text'].to_numpy(),\n",
        "                                                                        train_df_shuffled.drop(['id', 'comment_text'], axis=1).to_numpy(),\n",
        "                                                                        test_size=0.1,\n",
        "                                                                        random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'test.csv' file:                  id                                       comment_text\n",
            "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
            "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
            "\n",
            "'test_labels.csv' file:                  id  toxic  severe_toxic  obscene  threat  insult  \\\n",
            "0  00001cee341fdb12     -1            -1       -1      -1      -1   \n",
            "1  0000247867823ef7     -1            -1       -1      -1      -1   \n",
            "\n",
            "   identity_hate  \n",
            "0             -1  \n",
            "1             -1  \n",
            "\n",
            "'val_comment' dataframe: ['September 2006\\nThank you for experimenting with the page Construction on Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you want to do. Take a look at the welcome page if you would like to learn more about contributing to our encyclopedia.'\n",
            " \"Thank you. I'm on the link-deletion now.\"]\n",
            "\n",
            "'val_labels' dataframe: [[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"'test.csv' file: {test[:2]}\")\n",
        "print(f\"\\n'test_labels.csv' file: {test_labels[:2]}\")\n",
        "print(f\"\\n'val_comment' dataframe: {val_comment[:2]}\")\n",
        "print(f\"\\n'val_labels' dataframe: {val_labels[:2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.2 Make sure `test` & `test_labels` are in the same format as `val_comment` and `val_labels`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'test_comment' array: ['Thank you for understanding. I think very highly of you and would not revert without discussion.'\n",
            " ':Dear god this site is horrible.']\n",
            "\n",
            "'test_labels_final' array: [[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n",
            "\n",
            "'val_comment' dataframe: ['September 2006\\nThank you for experimenting with the page Construction on Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you want to do. Take a look at the welcome page if you would like to learn more about contributing to our encyclopedia.'\n",
            " \"Thank you. I'm on the link-deletion now.\"]\n",
            "\n",
            "'val_labels' dataframe: [[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Filter out rows with invalid labels (-1 in any column) from `test_labels`\n",
        "test_labels_clean = test_labels[test_labels.iloc[:, 1:].min(axis=1) != -1]\n",
        "\n",
        "# Merge test with test_labels_clean on `id` to ensure alignment\n",
        "test_clean = pd.merge(test, test_labels_clean, on='id')\n",
        "\n",
        "# Extract test comments (equivalent to val_comment)\n",
        "test_comment = test_clean['comment_text'].to_numpy()\n",
        "\n",
        "# Extract test labels (same as val_labels) and drop cols 'id' and other\n",
        "test_labels_final = test_clean.drop(['id', 'comment_text'], axis=1).to_numpy()\n",
        "\n",
        "# Check output\n",
        "print(f\"'test_comment' array: {test_comment[:2]}\")\n",
        "print(f\"\\n'test_labels_final' array: {test_labels_final[:2]}\")\n",
        "print(f\"\\n'val_comment' dataframe: {val_comment[:2]}\")\n",
        "print(f\"\\n'val_labels' dataframe: {val_labels[:2]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Generate Predictions on test files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 111s 55ms/step - loss: 0.0758 - accuracy: 0.9976\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.07576501369476318, 0.9975929260253906]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loaded_model.evaluate(test_comment, test_labels_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 86s 42ms/step\n"
          ]
        }
      ],
      "source": [
        "test_predictions_prob = loaded_model.predict(test_comment)\n",
        "\n",
        "test_predictions = (test_predictions_prob > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(test_predictions[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Print Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.61      0.65      6090\n",
            "           1       0.41      0.08      0.13       367\n",
            "           2       0.75      0.55      0.64      3691\n",
            "           3       0.00      0.00      0.00       211\n",
            "           4       0.66      0.47      0.55      3427\n",
            "           5       0.00      0.00      0.00       712\n",
            "\n",
            "   micro avg       0.70      0.51      0.59     14498\n",
            "   macro avg       0.42      0.29      0.33     14498\n",
            "weighted avg       0.65      0.51      0.57     14498\n",
            " samples avg       0.05      0.05      0.05     14498\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ILLEGEAR\\anaconda3\\envs\\py3900\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\ILLEGEAR\\anaconda3\\envs\\py3900\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\ILLEGEAR\\anaconda3\\envs\\py3900\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\ILLEGEAR\\anaconda3\\envs\\py3900\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels_final, test_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Save into `submission.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(63978, 6)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert predictions to a DataFrame with appropriate column names\n",
        "test_predictions_df = pd.DataFrame(\n",
        "    test_predictions, \n",
        "    columns=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        ")\n",
        "\n",
        "# Combine the 'id' column from the test DataFrame with the predictions DataFrame\n",
        "submission_df = pd.concat([test['id'], test_predictions_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the DataFrame to CSV\n",
        "submission_df.to_csv('predictions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "e4i71VCFS18c",
        "wpvvSOipTNF3"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3900",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
